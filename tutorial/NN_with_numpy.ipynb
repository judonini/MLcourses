{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Building a NN using numpy\n",
    "\n",
    "A fully-connected ReLU network with one hidden layer and no biases, trained to\n",
    "predict y from x using Euclidean error.\n",
    "\n",
    "The model that we want to build has the following structure:\n",
    "$$\\hat{y}(x) = \\text{relu}(x.w_1).w_2,$$\n",
    "where $x$ and $y$ are the input and output features (of dimension 1000 and 10, respectively). Here the relu activation function is used and $w_1$ and $w_2$ are weight matrices.\n",
    "\n",
    "This implementation uses numpy to manually compute the forward pass, loss, and\n",
    "backward pass. A numpy array is a generic n-dimensional array; it does not know anything about\n",
    "deep learning or gradients or computational graphs, and is just a way to perform\n",
    "generic numeric computations.\n",
    "\n",
    "This example is adapted from: https://pytorch.org/tutorials/beginner/pytorch_with_examples.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward and backward pass\n",
    "\n",
    "Forward pass: $x \\rightarrow h= x.W_1 \\rightarrow \\hat{y} = \\text{relu}(h).W_2.$\n",
    "\n",
    "Cost and loss functions:\n",
    "* Cost: $E(W) = \\sum_{i=1}^N (\\hat{y} - y)^2$\n",
    "* $\\text{loss}: \\ell(\\hat{y},W) = (\\hat{y} - y)^2.$\n",
    "\n",
    "Backward pass: derivatives of loss function\n",
    "\n",
    "$$\\frac{\\partial \\ell}{\\partial W_2} = \\frac{\\partial \\ell}{\\partial \\hat{y}} \\frac{\\partial \\hat{y}}{\\partial W_2} = 2(\\hat{y} - y).\\text{relu}(h)$$\n",
    "\n",
    "$$\\frac{\\partial \\ell}{\\partial W_1} = \\frac{\\partial \\ell}{\\partial \\hat{y}} \\frac{\\partial \\hat{y}}{\\partial h} \\frac{\\partial h}{\\partial W_1} = 2(\\hat{y} - y).W_2. \\frac{\\partial \\text{relu}(h)}{\\partial h} .x$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 64      # N: input batch size\n",
    "D_in = 1000 # D_in: input dimension\n",
    "H = 100     # H: hidden layer dimension;\n",
    "D_out = 10  # D_out: output dimension\n",
    "\n",
    "# Create random input and output (target) training data\n",
    "x = np.random.randn(N, D_in)\n",
    "y = np.random.randn(N, D_out)\n",
    "\n",
    "# Randomly initialize weights (no bias terms)\n",
    "w1 = np.random.randn(D_in, H)\n",
    "w2 = np.random.randn(H, D_out)\n",
    "\n",
    "learning_rate = 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. First let's look at the dimension of data and weights. \n",
    "For this use e.g. print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: (64, 1000)\n",
      "w1: (1000, 100)\n",
      "w2: (100, 10)\n",
      "y: (64, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"x:\",x.shape)\n",
    "print(\"w1:\",w1.shape)\n",
    "print(\"w2:\",w2.shape)\n",
    "print(\"y:\",y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Forward pass: compute predicted y\n",
    "\n",
    "We want to compute: $\\hat{y} = \\text{relu}(x.w_1).w_2$, where the relu activation function is used.\n",
    "\n",
    "For this calculate (be careful of the matrix dimensions):\n",
    "* h = dot product of x and w1 (use .dot() function)\n",
    "* h_relu: $\\text{relu}(h)$ relu activation function (using np.maximum() function)\n",
    "* compute $\\hat{y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = x.dot(w1)                # dim (64,100)\n",
    "h_relu = np.maximum(h, 0)    # dim (64,100)\n",
    "y_pred = h_relu.dot(w2)      # dim (64,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate and print cost function\n",
    "* Cost: $E(w_1,w_2) = \\sum_{i=1}^N (\\hat{y_i} - y_i)^2$\n",
    "* $\\text{loss}: \\ell(\\hat{y},W) = (\\hat{y} - y)^2.$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total cost: 28188687.87677094\n"
     ]
    }
   ],
   "source": [
    "cost = np.square(y_pred - y).sum()\n",
    "print(\"total cost:\", cost)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Backward pass\n",
    "Compute gradients of $w_1$ and $w_2$ with respect to loss.\n",
    "\n",
    "Beware of matrices dimensions !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have: dim(x) = (64, 1000); dim($w_1$) = (1000, 100); dim($w_2$) = (100, 10); dim(y) = (64, 10). Therefore:\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\ell}{\\partial W_2} = [\\text{relu}(h)]^T \\cdot 2(\\hat{y} - y) & \\ \\rightarrow \\ \\text{dim = } (100,64) \\times (64,10) = (100,10) \\\\\n",
    "\\frac{\\partial \\ell}{\\partial W_1} = x^T \\cdot \\left( \\frac{\\partial \\text{relu}(h)}{\\partial h} \\cdot 2 (\\hat{y} - y) \\right) \\cdot W_2^T & \\ \\rightarrow \\ \\text{dim = } (1000,64) \\times (64,10) \\times (10,100) = (1000,100) \\\\\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backprop to compute gradients of w1 and w2 with respect to loss\n",
    "grad_y_pred = 2.0 * (y_pred - y)\n",
    "grad_w2 = h_relu.T.dot(grad_y_pred)\n",
    "grad_h_relu = grad_y_pred.dot(w2.T)\n",
    "grad_h = grad_h_relu.copy()\n",
    "grad_h[h < 0] = 0               # if h<0 then set grad_h=0\n",
    "grad_w1 = x.T.dot(grad_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Update weights $w_1$ and $w_2$\n",
    "Note: because of matrices dimensionality the gradients are already summed over all N data events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update weights\n",
    "w1 -= learning_rate * grad_w1\n",
    "w2 -= learning_rate * grad_w2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Repeat procedure\n",
    "\n",
    "The above procedure will be repeated 500 times. In addition we'll test the model on a validation set that is created in the same way as the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation set\n",
    "x_val = np.random.randn(N, D_in)\n",
    "y_val = np.random.randn(N, D_out)\n",
    "\n",
    "# Counters\n",
    "cost=[]\n",
    "counter=[]\n",
    "cost_val=[]\n",
    "\n",
    "niteration = 500\n",
    "\n",
    "for t in range(niteration):\n",
    "    # Forward pass: compute predicted y\n",
    "    h = x.dot(w1)\n",
    "    h_relu = np.maximum(h, 0)\n",
    "    y_pred = h_relu.dot(w2)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = np.square(y_pred - y).sum()\n",
    "    cost.append(loss)\n",
    "    counter.append(t)\n",
    "\n",
    "    ### compute loss for validation data\n",
    "    h_val = x_val.dot(w1)\n",
    "    h_relu_val = np.maximum(h_val, 0)\n",
    "    y_pred_val = h_relu_val.dot(w2)\n",
    "    loss_val = np.square(y_pred_val - y_val).sum()\n",
    "    cost_val.append(loss_val)\n",
    "    \n",
    "    # Backprop to compute gradients of w1 and w2 with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.T.dot(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.dot(w2.T)\n",
    "    grad_h = grad_h_relu.copy()\n",
    "    grad_h[h < 0] = 0                      # if h<0 then set grad_h=0\n",
    "    grad_w1 = x.T.dot(grad_h)\n",
    "\n",
    "    # Update weights\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Plot model performance\n",
    "Using matplotlib plot the evolution of cost as a function of the number of iterations.\n",
    "\n",
    "Conclude on the generalization of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f651ddfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(counter, cost, color='blue', label='train')\n",
    "plt.plot(counter, cost_val, color='green',label='validation')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('number of iterations')\n",
    "plt.ylabel('Cost')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: there is a clear overtraining for this simplistic example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple example of digit classification\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html#sphx-glr-auto-examples-classification-plot-digits-classification-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, metrics\n",
    "\n",
    "# The digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# The data that we are interested in is made of 8x8 images of digits, let's\n",
    "# have a look at the first 4 images, stored in the `images` attribute of the\n",
    "# dataset.  If we were working from image files, we could load them using\n",
    "# matplotlib.pyplot.imread.  Note that each image must have the same size. For these\n",
    "# images, we know which digit they represent: it is given in the 'target' of\n",
    "# the dataset.\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "\n",
    "# Separate in train and validation samples\n",
    "x = data[:n_samples // 2]\n",
    "y = digits.target[:n_samples // 2]\n",
    "\n",
    "x_val = data[n_samples // 2:]\n",
    "y_val = digits.target[n_samples // 2:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate in train and validation samples\n",
    "x = data[:100]\n",
    "y = digits.target[:100]\n",
    "\n",
    "x_val = data[100:]\n",
    "y_val = digits.target[100:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_in = 64 # D_in: input dimension\n",
    "H = 100     # H: hidden layer dimension;\n",
    "D_out = 1  # D_out: output dimension\n",
    "\n",
    "# Reinitialize weights to random number\n",
    "w1 = np.random.randn(D_in, H)\n",
    "w2 = np.random.randn(H, D_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost=[]\n",
    "counter=[]\n",
    "cost_val=[]\n",
    "\n",
    "niteration = 500\n",
    "\n",
    "for t in range(niteration):\n",
    "    # Forward pass: compute predicted y\n",
    "    h = x.dot(w1)\n",
    "    h_relu = np.maximum(h, 0)\n",
    "    y_pred = h_relu.dot(w2)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = np.square(y_pred - y).sum()\n",
    "    cost.append(loss)\n",
    "    counter.append(t)\n",
    "\n",
    "    ### compute loss for validation data\n",
    "    h_val = x_val.dot(w1)\n",
    "    h_relu_val = np.maximum(h_val, 0)\n",
    "    y_pred_val = h_relu_val.dot(w2)\n",
    "    loss_val = np.square(y_pred_val - y_val).sum()\n",
    "    cost_val.append(loss_val)\n",
    "    \n",
    "    # Backprop to compute gradients of w1 and w2 with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.T.dot(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.dot(w2.T)\n",
    "    grad_h = grad_h_relu.copy()\n",
    "    grad_h[h < 0] = 0                      # if h<0 then set grad_h=0\n",
    "    grad_w1 = x.T.dot(grad_h)\n",
    "\n",
    "    # Update weights\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = x.dot(w1)\n",
    "h_relu = np.maximum(h, 0)\n",
    "y_pred = h_relu.dot(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

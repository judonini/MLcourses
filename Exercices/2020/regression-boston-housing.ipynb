{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston Housing Data\n",
    "\n",
    "The Boston Housing dataset is a classic example used in Machine Learning. This dataset contains information collected in the 1970's by the U.S Census Service concerning housing in the area of Boston. It consists of 13 features and a target (the housing price in $1000's). There are 506 instances.\n",
    "\n",
    "The objective of this tutorial is to build a linear model to predict the homes price given a set of feature. \n",
    "\n",
    "Feature Information:\n",
    "\n",
    "    0. CRIM      per capita crime rate by town\n",
    "    1. ZN        proportion of residential land zoned for lots over \n",
    "                 25,000 sq.ft.\n",
    "    2. INDUS     proportion of non-retail business acres per town\n",
    "    3. CHAS      Charles River dummy variable (= 1 if tract bounds \n",
    "                 river; 0 otherwise)\n",
    "    4. NOX       nitric oxides concentration (parts per 10 million)\n",
    "    5. RM        average number of rooms per dwelling\n",
    "    6. AGE       proportion of owner-occupied units built prior to 1940\n",
    "    7. DIS       weighted distances to five Boston employment centres\n",
    "    8. RAD       index of accessibility to radial highways\n",
    "    9. TAX      full-value property-tax rate per \\$10,000\n",
    "    10. PTRATIO  pupil-teacher ratio by town\n",
    "    11. B        1000(Bk - 0.63)^2 where Bk is the proportion of [people of African American descent] by town\n",
    "    12. LSTAT    % lower status of the population\n",
    "\n",
    "Target:\n",
    "    0. Price     Median value of owner-occupied homes in $1000's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: https://machinelearningmastery.com/ridge-regression-with-python/\n",
    "\n",
    "https://towardsdatascience.com/ridge-and-lasso-regression-a-complete-guide-with-python-scikit-learn-e20e34bcbf0b\n",
    "        \n",
    "About Kfold CV: https://machinelearningmastery.com/k-fold-cross-validation/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries\n",
    "\n",
    "Libraries needed for this exercice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from pandas import read_csv\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the dataset\n",
    "\n",
    "We will import the housing data from the scikit-learn library, then we load the data into a pandas dataframe using pd.DataFrame.\n",
    "\n",
    "a) How many lines and column does this dataset have ? Show the first 5 examples.\n",
    "\n",
    "b) Check there are no missing values. For this use `isnull().sum()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "# Load data\n",
    "boston = load_boston()\n",
    "boston_df = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "boston_df.insert(0, 'Price', boston.target)\n",
    "\n",
    "# a) Show some examples\n",
    "\n",
    "\n",
    "# b) Check if there are any missing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data exploration\n",
    "\n",
    "We first assign features values to numpy array $X$ and target values to numpy array $y$\n",
    "\n",
    "a) check the dimension of $X$ and $y$\n",
    "\n",
    "b) Make histograms for each features and for the target\n",
    "\n",
    "c) Show scatter plots of each feature vs the target (optional: calculate correlation coefficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston.data   # Features\n",
    "y = boston.target # Target\n",
    "\n",
    "# a) X and y dimensions\n",
    "\n",
    "\n",
    "# b) Show histograms\n",
    "\n",
    "\n",
    "# c) Scatter plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split data in train and test samples\n",
    "\n",
    "We now split the total dataset in a train and a test sample using scikit-learn.\n",
    "\n",
    "Look at the size of each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Linear regression\n",
    "\n",
    "Now let's construct a predictive model using linear regression:\n",
    "\n",
    "$$y_{pred} = w_0 + \\sum_{i=1}^{N=13} w_i X_i$$\n",
    "\n",
    "For this we use the scikit-learn model described here: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "\n",
    "a) Fit the linear regression model using the training dataset and print the parameters (weights and bias term) of the fit.\n",
    "\n",
    "b) Get the predicted model output, `y_train_pred`, using the training dataset. Make a scatter plot of the true target value, `y_train`, vs the predicted value, `y_train_pred`.\n",
    "\n",
    "c) Calculate the root mean square error (RMS) between `y_train` and `y_train_pred`. For this you can use the scikit-learn function `mean_squared_error()`.\n",
    "\n",
    "d) Finally we apply the model to the test dataset: repeat steps b) and c) with the test sample. Do you think that the model is acceptable ? Is there an overfitting problem ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit of the model\n",
    "model1 = LinearRegression()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ridge penalty (a.k.a L2 norm)\n",
    "\n",
    "Let's see if a penalized linear algorithm can improve the modelling and prediction of the data. For this we use Ridge regression (also called L2 norm) which adds a penalty term to the fit model:\n",
    "\n",
    "$$y_{pred} = w_0 + \\sum_{i=1}^{N=13} w_i X_i + \\lambda \\sum_{i=0}^{N=13} w_i^2$$\n",
    "\n",
    "See the scikit-learn implementation https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html\n",
    "\n",
    "a) Train the model using the training dataset and a $\\lambda$ regularization parameter =1\n",
    "\n",
    "b) Apply the algorithm to the test data and check the quality of the model. Do you see any improvement in the data modelling and prediction ? Try other values of $\\lambda$.\n",
    "\n",
    "c) Optional, try Lasso penalty: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html. Does it help ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model2 = Ridge(alpha=1) # Alpha sets the lambda (yes...) hyperparameter \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Estimating model performance: Cross-validation\n",
    "\n",
    "Instead of splitting the dataset in one training and one test samples we can use cross-validation to better determine the performance of a fit model. For this we apply the following [procedure](https://machinelearningmastery.com/k-fold-cross-validation/):\n",
    "- Shuffle the dataset randomly.\n",
    "- Split the dataset into k groups\n",
    "- For each unique group:\n",
    "  - Take the group as test data set\n",
    "  - Take the k-1 remaining groups as a training data set\n",
    "  - Fit a model on the training set and evaluate it on the test set\n",
    "  - Retain the evaluation score and discard the model\n",
    "- Summarize the skill of the model using the sample of model evaluation scores\n",
    "\n",
    "a) Look at the example below, what are the different parameters ? To what corresponds the output ?\n",
    "\n",
    "b) Apply the cross-validation to the other models. Can you say if one is more performant than the other ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=False)\n",
    "scores = cross_val_score(model1, X, y, scoring='neg_mean_squared_error', cv=cv)\n",
    "scores = np.absolute(scores)\n",
    "print('Mean RMS: %.2f +- %.2f' % (np.mean(np.sqrt(scores)),np.std(np.sqrt(scores))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

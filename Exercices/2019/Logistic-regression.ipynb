{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression example\n",
    "\n",
    "We will use Logistic Regression to calculate the probability for a student to pass an exam given the number of hours of study and number of hours slept:\n",
    "\n",
    "$$p(\\text{passed}) = \\sigma(w_0 + w_1 \\cdot \\text{hours studied} + w_2 \\cdot \\text{hours slept})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize # for fit\n",
    "%matplotlib inline\n",
    "rng = np.random.RandomState(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read data\n",
    "\n",
    "We first start to read a `cvs` file containing, for each student, the number of hours studied and slept (=the `features`) and the result (=the `labels`) of the exam: 0 (Failed) or 1 (passed).\n",
    "\n",
    "a) Separate the sample in student that passed the exam and student that failed the exam:\n",
    "```python\n",
    "labels = ...\n",
    "student_passed = ...\n",
    "student_failed = ...\n",
    "```\n",
    "\n",
    "b) Show on a figure for each student the number of hours slept as a function of the number of hours studied. Use a blue marker for students that passed and a red marker for those who failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and read file\n",
    "from numpy import genfromtxt\n",
    "my_data = genfromtxt('data_classification2.csv', delimiter=',')\n",
    "print('%10s %10s %8s'% ('Studied', 'Slept', 'Passed'))\n",
    "\n",
    "# Print first 10 entries\n",
    "print(my_data[:10,:])\n",
    "\n",
    "# CONTINUE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Separate data in train and test sample\n",
    "\n",
    "a) You'll note below that we add a column of \"1\" to the vector of features ${\\bf x}$. Why do we do that ? The vector ${\\bf x}$ is redefined as ${\\bf x^*}$:\n",
    "$${\\bf x} \\rightarrow {\\bf x^*}$$\n",
    "\n",
    "b) Separate the sample in two: the first 500 entries for training and the remaining 500 entries for testing.\n",
    "```python\n",
    "features_train = ...\n",
    "labels_train = ...\n",
    "features_test = ...\n",
    "labels_test = ...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data features: [1, studied, slept]\n",
    "features = my_data[:,0:2]\n",
    "bias = np.ones(shape=(len(features),1))\n",
    "features = np.append(bias, features, axis=1)\n",
    "\n",
    "# N examples for train and test\n",
    "N=500\n",
    "\n",
    "# CONTINUE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sigmoid function\n",
    "\n",
    "For training the Logistic Regression we'll need the sigmoid function and its derivative\n",
    "\n",
    "a) Write two functions, `sigmoid(x)` and `dsig(x)` that returns, respectively $\\sigma(x)$ and $\\frac{\\text{d} \\sigma}{\\text{d} x}(x)$.\n",
    "\n",
    "b) Represent graphically both functions on the same figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Function definitions\n",
    "\n",
    "The predictive model for a feature ${\\bf x}$ is given by the function:\n",
    "\n",
    "$$f({\\bf x}) = \\sigma \\left( w_0 + \\sum_{i=1}^D w_i x_i \\right) = \\sigma \\left(\\sum_{i=0}^D w_i x^*_i \\right)$$\n",
    "\n",
    "The cost function used in the Logistic Regression is the cross-entropy:\n",
    "\n",
    "$$E({\\bf w}) = - \\frac{1}{N}\\sum_{j=1}^N t_j \\log( f({\\bf x_j})) + (1-t_j) \\log( 1 - f({\\bf x_j}))$$\n",
    "\n",
    "The gradient of the cross-entropy function is:\n",
    "$$\n",
    "\\vec{\\nabla} E({\\bf w}) = \\frac{1}{N}\\sum_{j=1}^N \\left[ f({\\bf x_j}) - t_j \\right] {\\bf x^*_j} \\rightarrow\n",
    "\\begin{cases}\n",
    "\\frac{\\partial E({\\bf w})}{\\partial w_0} = \\frac{1}{N}\\sum_{j=1}^N \\left[ f({\\bf x_j}) - t_j \\right] \\\\\\\\\n",
    "\\frac{\\partial E({\\bf w})}{\\partial w_1} = \\frac{1}{N}\\sum_{j=1}^N \\left[ f({\\bf x_j}) - t_j \\right] x_{j1} \\\\\n",
    "\\vdots \\\\\n",
    "\\frac{\\partial E({\\bf w})}{\\partial w_D} = \\frac{1}{N}\\sum_{j=1}^N \\left[ f({\\bf x_j}) - t_j \\right] x_{jD}\n",
    "\\end{cases}$$\n",
    "\n",
    "Look at all the functions below and explain for each what they do.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(features, weights):\n",
    "    '''\n",
    "    Returns 1D array of probabilities\n",
    "    that the class label == 1\n",
    "    '''\n",
    "    z = np.dot(features, weights)\n",
    "    return sigmoid(z)\n",
    "\n",
    "\n",
    "def cost_function(features, labels, weights):\n",
    "    '''\n",
    "    Cross-Entropy cost function\n",
    "\n",
    "    Features:(100,3)\n",
    "    Labels: (100,1)\n",
    "    Weights:(3,1)\n",
    "    Returns 1D matrix of predictions\n",
    "    Cost = sum ( labels*log(predictions) + (1-labels)*log(1-predictions) ) / len(labels)\n",
    "    '''\n",
    "    observations = len(labels)\n",
    "\n",
    "    predictions = predict(features, weights)\n",
    "\n",
    "    #Take the error when label=1\n",
    "    class1_cost = -labels*np.log(predictions)\n",
    "\n",
    "    #Take the error when label=0\n",
    "    class2_cost = (1-labels)*np.log(1-predictions)\n",
    "\n",
    "    #Take the sum of both costs\n",
    "    cost = class1_cost - class2_cost\n",
    "\n",
    "    #Take the average cost\n",
    "    cost = cost.sum()/observations\n",
    "\n",
    "    return cost\n",
    "\n",
    "\n",
    "def update_weights(features, labels, weights, lr):\n",
    "    '''\n",
    "    Vectorized Gradient Descent\n",
    "\n",
    "    Features:(100, 3)\n",
    "    Labels: (100, 1)\n",
    "    Weights:(3, 1)\n",
    "    '''\n",
    "    N = len(features)\n",
    "\n",
    "    #1 - Get Predictions\n",
    "    predictions = predict(features, weights)\n",
    "\n",
    "    #2 Transpose features from (100, 3) to (3, 100)\n",
    "    # So we can multiply w the (100,1)  cost matrix.\n",
    "    # Returns a (3,1) matrix holding 3 partial derivatives --\n",
    "    # one for each feature -- representing the aggregate\n",
    "    # slope of the cost function across all observations\n",
    "    gradient = np.dot(features.T,  predictions - labels)\n",
    "    \n",
    "    #3 Take the average cost derivative for each feature\n",
    "    gradient /= N\n",
    "\n",
    "    #4 - Multiply the gradient by our learning rate\n",
    "    gradient *= lr\n",
    "    \n",
    "    #5 - Subtract from our weights to minimize cost\n",
    "    weights -= gradient\n",
    "\n",
    "    return weights\n",
    "\n",
    "\n",
    "def decision_boundary(prob):\n",
    "    \"\"\"\n",
    "    Decision boundary\n",
    "    \"\"\"\n",
    "    return 1 if prob >= .5 else 0\n",
    "\n",
    "def classify(predictions):\n",
    "    '''\n",
    "    Convert probabilities to classes\n",
    "    input  - N element array of predictions between 0 and 1\n",
    "    output - N element array of 0s (False) and 1s (True)\n",
    "    '''\n",
    "    decision_boundary = np.vectorize(decision_boundary)\n",
    "    return decision_boundary(predictions).flatten()\n",
    "\n",
    "def train(features, labels, weights, lr, iters):\n",
    "    \"\"\"\n",
    "    Training using gradient descent\n",
    "    \"\"\"\n",
    "    cost_history = []\n",
    "\n",
    "    for i in range(iters):\n",
    "        weights = update_weights(features, labels, weights, lr)\n",
    "\n",
    "        #Calculate error for auditing purposes\n",
    "        cost = cost_function(features, labels, weights)\n",
    "        cost_history.append(cost)\n",
    "\n",
    "        # Log Progress\n",
    "        #if i % 1000 == 0:\n",
    "        #    print(\"iter: \"+str(i) + \" cost: \"+str(cost))\n",
    "\n",
    "    return weights, cost_history\n",
    "\n",
    "def accuracy(predicted_labels, actual_labels):\n",
    "    \"\"\"\n",
    "    Accuracy measures how correct our predictions were: compare predicted labels \n",
    "    to true labels and divide by the total.\n",
    "    \"\"\"\n",
    "    diff = predicted_labels - actual_labels\n",
    "    return 1.0 - (float(np.count_nonzero(diff)) / len(diff))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training\n",
    "\n",
    "Calculate the weights with gradient descent for 20000 steps. Plot cost function evolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights\n",
    "weights = np.array([0.0,0.0,0.0])\n",
    "\n",
    "# Caculate weights with gradient descent\n",
    "Niter=20000\n",
    "learning_speed = 0.1\n",
    "\n",
    "# CONTINUE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Results\n",
    "\n",
    "Run the steps below. Interpret these results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_boundary = np.vectorize(decision_boundary)\n",
    "\n",
    "# train dataset\n",
    "predicted_probabilities_train = predict(features_train, weights)\n",
    "predicted_labels_train = decision_boundary(predicted_probabilities_train).flatten()\n",
    "accuracy_prediction_train = accuracy(decision_boundary(predicted_labels_train), labels_train)\n",
    "print('Accuracy of predictions (train dataset): %.3f' % accuracy_prediction_train)\n",
    "\n",
    "# test dataset\n",
    "predicted_probabilities_test = predict(features_test, weights)\n",
    "predicted_labels_test = decision_boundary(predicted_probabilities_test).flatten()\n",
    "accuracy_prediction_test = accuracy(decision_boundary(predicted_labels_test), labels_test)\n",
    "print('Accuracy of predictions (test dataset): %.3f' % accuracy_prediction_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted probability distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "bins = np.linspace(0,1,15)\n",
    "n, bins, patches = plt.hist(predicted_probabilities_train[labels_train>0.5], bins, alpha=0.5, label='Train P', normed=1)\n",
    "plt.hist(predicted_probabilities_train[labels_train<0.5], bins, alpha=0.5, label='Train N', normed=1)\n",
    "plt.hist(predicted_probabilities_test[labels_test>0.5], bins, alpha=0.5, label='Test P', normed=1,histtype='step',lw=4)\n",
    "plt.hist(predicted_probabilities_test[labels_test<0.5], bins, alpha=0.5, label='Test N', normed=1,histtype='step',lw=4)\n",
    "plt.xlabel('Predicted probabilities',fontsize=18)\n",
    "plt.legend(loc='best',fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "#target = np.concatenate((np.zeros(x_train.shape[0]),np.ones(x_test.shape[0])))\n",
    "#scores = np.concatenate((norm_train,norm_test))  \n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "# Train set                   \n",
    "fp, vp, thresholds = roc_curve(labels_train,predicted_probabilities_train,pos_label=1,drop_intermediate='False')\n",
    "roc_auc = auc(fp, vp)\n",
    "plt.plot(fp,vp,color='red',label='ROC curve Train (AUC = %0.4f)'%(roc_auc))\n",
    "# Test set                   \n",
    "fp, vp, thresholds = roc_curve(labels_test,predicted_probabilities_test,pos_label=1,drop_intermediate='False')\n",
    "roc_auc = auc(fp, vp)\n",
    "plt.plot(fp,vp,color='green',label='ROC curve Test (AUC = %0.4f)'%(roc_auc))\n",
    "\n",
    "plt.xlabel('False Positive Rate',fontsize=18)\n",
    "plt.ylabel('True Positive Rate',fontsize=18)\n",
    "plt.plot([0, 1],[0, 1],linestyle='--',color=(0.6, 0.6, 0.6),label='Random guess')\n",
    "plt.grid()\n",
    "plt.legend(loc=\"best\",fontsize=16)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"images/ROC.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "LABELS = [\"Pass\", \"Fail\"]\n",
    "\n",
    "threshold = 0.2\n",
    "\n",
    "y_pred = [1 if e > threshold else 0 for e in predicted_probabilities_test]\n",
    "conf_matrix = confusion_matrix(labels_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(conf_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\");\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.show()\n",
    "\n",
    "NN = conf_matrix[0,0]\n",
    "NF = conf_matrix[0,1]\n",
    "FN = conf_matrix[1,0]\n",
    "FF = conf_matrix[1,1]\n",
    "print('False positive rate = %.2f %%' % (NF/(NN+NF)*100))\n",
    "print('True positive rate = %.2f %%' % (FF/(FN+FF)*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
